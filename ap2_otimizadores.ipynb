{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HannaRF/DeepLearning/blob/main/ap2_otimizadores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Practical Session 2 - Optimizers\n",
        "\n",
        "**Teacher:** Dario Oliveira\n",
        "\n",
        "**T.A.:** João Alcindo\n",
        "\n",
        "\n",
        "\n",
        "In this practical session, we will explore how different optimizers can impact the training and performance of a neural network model. Choosing the right optimizer is crucial for achieving good performance and ensuring that the model converges efficiently.\n",
        "\n",
        "#### Objectives of the Session\n",
        "\n",
        "1. **Understand the Function of Optimizers in Practice**: Optimizers are algorithms that adjust the model's parameters to minimize the loss function. We will analyze how different optimizers work and how they can influence the training process.\n",
        "\n",
        "2. **Compare Various Optimizers**: We will test and compare several optimizers, including Adam, SGD, RMSprop, Adagrad, and their variations with Momentum and Nesterov. We will observe how each affects the convergence speed and model accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ALVlQEWkGQyl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "tqp_GikxG7fN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchsummary import summary\n"
      ],
      "metadata": {
        "id": "G82KBupzyVoE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set the GPU"
      ],
      "metadata": {
        "id": "MNb5CTgOG-UK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir o dispositivo: usa GPU se disponível, senão usa CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW8EHf1J6eie",
        "outputId": "74c8ab0a-f289-431e-8466-5ed24d649071"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and preprocessing"
      ],
      "metadata": {
        "id": "BWUZV0IKHEoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformações para o dataset MNIST (normalização)\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Carregar o dataset MNIST\n",
        "full_train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Dividir o conjunto de treino em treino e validação (80% treino, 20% validação)\n",
        "train_size = int(0.8 * len(full_train_dataset))\n",
        "val_size = len(full_train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
        "\n",
        "# DataLoader para treino, validação e teste\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcG8CZ4X6efy",
        "outputId": "7fdf3277-3110-4cbf-c068-90fe7539851d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:02<00:00, 4553179.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 132613.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:01<00:00, 1258654.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3008611.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Neural Network"
      ],
      "metadata": {
        "id": "-Lztl4BhHNjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Definição do modelo em PyTorch\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 256)  # MNIST tem imagens 28x28\n",
        "        self.fc2 = nn.Linear(256, 512)\n",
        "        self.fc3 = nn.Linear(512, 256)\n",
        "        self.fc4 = nn.Linear(256, 10)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)  # Flatten a entrada (batch_size, 1, 28, 28) para (batch_size, 784)\n",
        "        x = self.sigmoid(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.sigmoid(self.fc4(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "LZosjwdh6ed0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation Functions"
      ],
      "metadata": {
        "id": "RqH-LaxbIC6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função de treinamento\n",
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, labels in loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)  # Mover dados para o dispositivo\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "# Função de avaliação (usada para validação e teste)\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            pred = outputs.argmax(dim=1, keepdim=True)  # Obtém as previsões\n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "    return total_loss / len(loader), correct / len(loader.dataset)\n"
      ],
      "metadata": {
        "id": "9mkmIARd6eaI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Optimizers and Loss Criterion"
      ],
      "metadata": {
        "id": "VDTbsxuNIVr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Inicializar o modelo e mover para o dispositivo apropriado\n",
        "model = SimpleNN().to(device)\n",
        "\n",
        "# Otimizadores disponíveis (comentados)\n",
        "\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)  # SGD\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)  # SGD com Momentum\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)  # SGD com Nesterov\n",
        "# optimizer = optim.RMSprop(model.parameters(), lr=0.001)  # RMSprop\n",
        "# optimizer = optim.Adagrad(model.parameters(), lr=0.01)  # Adagrad\n",
        "\n",
        "\n",
        "# Critério de perda\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "aeX5UT3l6eXo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary"
      ],
      "metadata": {
        "id": "-Ctl8XcuIapJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (1,28,28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn2URMUIBB_B",
        "outputId": "806fa596-70f7-4369-e382-4bdc2383aecd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 256]         200,960\n",
            "           Sigmoid-2                  [-1, 256]               0\n",
            "            Linear-3                  [-1, 512]         131,584\n",
            "              ReLU-4                  [-1, 512]               0\n",
            "            Linear-5                  [-1, 256]         131,328\n",
            "              ReLU-6                  [-1, 256]               0\n",
            "            Linear-7                   [-1, 10]           2,570\n",
            "           Sigmoid-8                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 466,442\n",
            "Trainable params: 466,442\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.02\n",
            "Params size (MB): 1.78\n",
            "Estimated Total Size (MB): 1.80\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model"
      ],
      "metadata": {
        "id": "enapauRpIdGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Exemplo de uso: Treinamento com conjunto de validação\n",
        "for epoch in range(1, 11):  # Treinando por 10 épocas\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
        "    val_loss, val_accuracy = evaluate(model, val_loader, criterion)\n",
        "\n",
        "    print(f'Epoch {epoch}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}, Val Accuracy = {val_accuracy * 100:.2f}%')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5oFQWEi6eUv",
        "outputId": "bf1cc084-e432-48d8-8c9e-7adf0f540cc3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 2.3008, Val Loss = 2.2993, Val Accuracy = 11.29%\n",
            "Epoch 2: Train Loss = 2.2975, Val Loss = 2.2960, Val Accuracy = 11.29%\n",
            "Epoch 3: Train Loss = 2.2938, Val Loss = 2.2916, Val Accuracy = 11.29%\n",
            "Epoch 4: Train Loss = 2.2879, Val Loss = 2.2836, Val Accuracy = 11.41%\n",
            "Epoch 5: Train Loss = 2.2761, Val Loss = 2.2659, Val Accuracy = 18.31%\n",
            "Epoch 6: Train Loss = 2.2468, Val Loss = 2.2196, Val Accuracy = 36.20%\n",
            "Epoch 7: Train Loss = 2.1754, Val Loss = 2.1183, Val Accuracy = 47.81%\n",
            "Epoch 8: Train Loss = 2.0478, Val Loss = 1.9739, Val Accuracy = 61.26%\n",
            "Epoch 9: Train Loss = 1.9180, Val Loss = 1.8701, Val Accuracy = 64.98%\n",
            "Epoch 10: Train Loss = 1.8403, Val Loss = 1.8137, Val Accuracy = 63.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliação final no conjunto de teste\n",
        "test_loss, test_accuracy = evaluate(model, test_loader, criterion)\n",
        "print(f'Test Loss = {test_loss:.4f}, Test Accuracy = {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "KG9wgEjW6eRg",
        "outputId": "05db77b8-13ac-41e8-b48c-af7048e7476b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss = 1.8114, Test Accuracy = 64.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise\n",
        "\n",
        "Try other training parameters, following this table:\n",
        "\n",
        "| Optimizer         | Learning Rate |\n",
        "|-------------------|---------------|\n",
        "| SGD               | 0.01          |\n",
        "| SGD + Momentum    | 0.01          |\n",
        "| Nesterov Momentum | 0.01          |\n",
        "| Adagrad           | 0.01          |\n",
        "| RMSProp           | 0.01          |\n",
        "| RMSProp           | 0.1           |\n",
        "| Adam              | 0.01          |\n",
        "| Adam              | 0.0001        |\n",
        "| Adam              | 0.1           |\n",
        "| Adam              | 0.3           |\n",
        "| SGD               | 0.3           |\n",
        "| Adagrad           | 0.3           |\n",
        "| RMSProp           | 0.3           |\n"
      ],
      "metadata": {
        "id": "jalxOFz4Irsy"
      }
    }
  ]
}