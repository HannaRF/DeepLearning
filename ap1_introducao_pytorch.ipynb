{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HannaRF/DeepLearning/blob/main/ap1_introducao_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aula Prática 1 - Introdução a Pytorch\n",
        "\n",
        "### Professor : Dário Oliveira\n",
        "### Monitor : João Alcindo\n"
      ],
      "metadata": {
        "id": "3tENFVw2BLQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ufElIqiaN1Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## O que é PyTorch?\n",
        "\n",
        "PyTorch é uma biblioteca open-source de aprendizado profundo (deep learning) desenvolvida pelo laboratório de pesquisa em inteligência artificial do Facebook, agora conhecido como Meta AI. Lançada em 2016, ela se tornou uma das bibliotecas mais populares para construção de modelos de aprendizado de máquina e aprendizado profundo."
      ],
      "metadata": {
        "id": "99xSGserLAT4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Tensors](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)\n",
        "\n",
        "Em PyTorch, um tensor é a estrutura de dados fundamental e pode ser visto como uma generalização de matrizes e vetores para dimensões arbitrárias. Assim como arrays em NumPy, tensores em PyTorch podem ser de várias dimensões:\n",
        "\n",
        "* **Escalar:** Um tensor de zero dimensões (um único número, como 3 ou -5.6).\n",
        "* **Vetor:** Um tensor de uma dimensão (por exemplo, [1.0, 2.0, 3.0]).\n",
        "* **Matriz:** Um tensor de duas dimensões (como uma tabela de valores ou uma imagem em tons de cinza).\n",
        "* **Tensor de Alta Dimensão:** Um tensor com três ou mais dimensões, como uma imagem RGB (altura, largura, canal) ou uma coleção de dados temporais."
      ],
      "metadata": {
        "id": "54Y637B3MC8F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCw4kMUeBDym",
        "outputId": "b04880c2-6b2d-4d7a-a319-440bfd9ab596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.1400)\n",
            "tensor([1., 2., 3.])\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "tensor([[[1., 2.],\n",
            "         [3., 4.]],\n",
            "\n",
            "        [[5., 6.],\n",
            "         [7., 8.]]])\n"
          ]
        }
      ],
      "source": [
        "# Criando um tensor escalar\n",
        "scalar = torch.tensor(3.14)\n",
        "print(scalar)\n",
        "\n",
        "# Criando um vetor (tensor de 1 dimensão)\n",
        "vector = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(vector)\n",
        "\n",
        "# Criando uma matriz (tensor de 2 dimensões)\n",
        "matrix = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "print(matrix)\n",
        "\n",
        "# Criando um tensor 3D\n",
        "tensor_3d = torch.tensor([[[1.0, 2.0], [3.0, 4.0]], [[5.0, 6.0], [7.0, 8.0]]])\n",
        "print(tensor_3d)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adição\n",
        "a = torch.tensor([1.0, 2.0, 3.0])\n",
        "b = torch.tensor([4.0, 5.0, 6.0])\n",
        "c = a + b\n",
        "print(c)\n",
        "\n",
        "# Multiplicação Element-wise\n",
        "d = a * b\n",
        "print(d)\n",
        "\n",
        "# Produto de Matrizes\n",
        "matrix1 = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "matrix2 = torch.tensor([[5.0, 6.0], [7.0, 8.0]])\n",
        "\n",
        "matrix_prod = torch.matmul(matrix1, matrix2)\n",
        "print(matrix_prod)\n",
        "\n",
        "# Outra maneira de escrever\n",
        "matrix_prod2 = matrix1 @ matrix2\n",
        "print(matrix_prod2)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHVRDkRROM88",
        "outputId": "f8786d27-ae92-415c-ccbb-3f7aa810b92f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 7., 9.])\n",
            "tensor([ 4., 10., 18.])\n",
            "tensor([[19., 22.],\n",
            "        [43., 50.]])\n",
            "tensor([[19., 22.],\n",
            "        [43., 50.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape (mudando a forma do tensor)\n",
        "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "reshaped_tensor = tensor.view(3, 2)  # Redimensionando para 3x2\n",
        "print(reshaped_tensor)\n",
        "\n",
        "# Slicing (fatiando o tensor)\n",
        "tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "sliced_tensor = tensor[:2, 1:]  # Pegando as duas primeiras linhas e colunas a partir da segunda\n",
        "print(sliced_tensor)\n",
        "\n",
        "# Concatenando Tensores\n",
        "tensor1 = torch.tensor([[1, 2]])\n",
        "tensor2 = torch.tensor([[3, 4]])\n",
        "concatenated_tensor = torch.cat((tensor1, tensor2), dim=0)  # Concatenando ao longo da dimensão 0 (linhas)\n",
        "print(concatenated_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrnkqxbqOfjB",
        "outputId": "ad77b4de-d8dc-4322-afc0-eee6b6e4229c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "tensor([[2, 3],\n",
            "        [5, 6]])\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparação com Arrays NumPy\n",
        "\n",
        "PyTorch tensores são semelhantes aos arrays do NumPy, mas com uma vantagem importante: eles podem ser usados em GPUs para acelerar as operações computacionais intensivas. Além disso, PyTorch oferece suporte automático para backpropagation usando o módulo `autograd`, que calcula automaticamente os gradientes para treinamento de redes neurais."
      ],
      "metadata": {
        "id": "ngaJ48vEBKbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# De Tensor para NumPy\n",
        "tensor = torch.tensor([1.0, 2.0, 3.0])\n",
        "numpy_array = tensor.numpy()\n",
        "print(numpy_array)\n",
        "\n",
        "# De NumPy para Tensor\n",
        "numpy_array = np.array([4.0, 5.0, 6.0])\n",
        "tensor_from_numpy = torch.tensor(numpy_array)\n",
        "print(tensor_from_numpy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nNbkrkNO3cf",
        "outputId": "ffc75d8b-3bb2-4e27-ca18-5ddaa031c76c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 2. 3.]\n",
            "tensor([4., 5., 6.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset e Dataloader\n",
        "\n",
        "### Dataset\n",
        "\n",
        "O módulo `torch.utils.data.Dataset` é uma abstração que permite carregar e manipular dados de maneira eficiente em PyTorch. Ele serve como uma interface para conjuntos de dados, fornecendo uma maneira de acessar e transformar dados de forma estruturada.\n",
        "\n",
        "### Dataloader\n",
        "\n",
        "O `DataLoader` é uma classe que facilita o manuseio de grandes datasets, fornecendo uma interface para iterar sobre eles de maneira eficiente, particularmente em mini-batches. Ele suporta a leitura de dados em paralelo usando múltiplos processos, embaralhamento dos dados, e carregamento de dados em mini-lotes (batches).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gJ1tH6j7BWll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando um Dataset :"
      ],
      "metadata": {
        "id": "K3fMD3ovY8R4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "XjHoTA3RZD5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "vm6vM2ESY_EE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e4caf16-0c21-4542-a0d9-45b0d37616d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:04<00:00, 6479794.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 133906.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 2518024.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 15865008.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iterando e Visualizando"
      ],
      "metadata": {
        "id": "YcbGjaCrZsRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "\n",
        "\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "7sCG6nM5Zwaq",
        "outputId": "66ceb05e-a9f1-4bb2-e722-a58363536229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Criando seu próprio Dataset\n",
        "\n",
        "Para criar um Dataset customizado em PyTorch, a classe deve implementar três funções principais: __init__, __len__, e __getitem__. Vamos examinar uma implementação onde as imagens do FashionMNIST são armazenadas em um diretório img_dir, e seus rótulos são armazenados separadamente em um arquivo CSV chamado annotations_file."
      ],
      "metadata": {
        "id": "TM5YRy1RaAoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset\n"
      ],
      "metadata": {
        "id": "uf-qAE0Vb5v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "gcIhnloOb5Nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  `__init__`\n",
        "A função `__init__` é executada uma única vez quando o objeto Dataset é instanciado. Nela, inicializamos o diretório que contém as imagens, o arquivo de anotações (CSV) e as transformações .\n",
        "\n",
        "Aqui está um exemplo de como o arquivo `labels.csv` poderia se parecer:\n",
        "\n",
        "```\n",
        "tshirt1.jpg, 0\n",
        "tshirt2.jpg, 0\n",
        "......\n",
        "ankleboot999.jpg, 9\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "#### `__len__`\n",
        "\n",
        "A função `__len__` retorna o número de amostras no dataset. É útil para determinar o tamanho do dataset, especialmente ao trabalhar com mini-batches durante o treinamento.\n",
        "\n",
        "#### `__getitem__`\n",
        "\n",
        "A função `__getitem__` carrega e retorna uma amostra do dataset no índice fornecido idx. Baseado nesse índice, a função:\n",
        "\n",
        "1. Identifica a localização da imagem no disco.\n",
        "2. Converte a imagem em um tensor usando read_image.\n",
        "3. Recupera o rótulo correspondente a partir dos dados CSV armazenados em self.img_labels.\n",
        "4. Aplica as funções de transformação na imagem e no rótulo (se aplicáveis).\n",
        "5. Retorna a imagem em formato tensor e o rótulo correspondente.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h5fLsD66cCpO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoader"
      ],
      "metadata": {
        "id": "XRuIjBCIoaeE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após criar um dataset, você pode usar o DataLoader para carregar os dados de forma eficiente durante o treinamento:"
      ],
      "metadata": {
        "id": "RKJS2ukrokla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "YXDWHREYobp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `batch_size`: Define o tamanho dos lotes (número de amostras por lote).\n",
        "* `shuffle`: Se True, embaralha os dados a cada epoch, garantindo que os dados sejam apresentados ao modelo em uma ordem diferente a cada vez."
      ],
      "metadata": {
        "id": "7jORCzplopIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmentation\n",
        "\n",
        "O PyTorch oferece a classe `torchvision.transforms` para aplicar transformações em imagens e outros tipos de dados durante o processo de carregamento. Essas transformações podem ser aplicadas diretamente no Dataset."
      ],
      "metadata": {
        "id": "ceKKQtUYo3Z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Definindo transformações\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalizando para o intervalo [-1, 1]\n",
        "])\n",
        "\n",
        "# Aplicando transformações a um dataset de imagens\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "NhB-P6Dno3y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construindo uma Rede Neural\n",
        "\n",
        "Em PyTorch, um modelo pode ser definido criando uma subclasse da classe `torch.nn.Module`. O processo de definição do modelo ocorre em duas etapas: primeiro, especificamos os parâmetros do modelo e, em seguida, descrevemos como esses parâmetros são aplicados às entradas. Para operações que não envolvem parâmetros treináveis, como funções de ativação (por exemplo, ReLU) ou operações como maxpooling, geralmente usamos o módulo `torch.nn.functional`.\n",
        "\n",
        "### Exemplo com uma camada oculta:\n",
        "\n"
      ],
      "metadata": {
        "id": "qLp_cUoaqmCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TwoLayerNet(nn.Module):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        \"\"\"\n",
        "        No construtor, instanciamos dois módulos nn.Linear e os atribuímos como\n",
        "        variáveis membro.\n",
        "\n",
        "        D_in: dimensão da entrada\n",
        "        H: dimensão da camada oculta\n",
        "        D_out: dimensão da saída\n",
        "        \"\"\"\n",
        "        super(TwoLayerNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(D_in, H)\n",
        "        self.linear2 = nn.Linear( H,D_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Na função forward, aceitamos uma variável de dados de entrada e devemos\n",
        "        retornar uma variável de dados de saída. Podemos usar módulos definidos no\n",
        "        construtor, bem como operadores arbitrários em variáveis.\n",
        "        \"\"\"\n",
        "        h_relu = F.relu(self.linear1(x))\n",
        "        y_pred = self.linear2(h_relu)\n",
        "        return y_pred\n"
      ],
      "metadata": {
        "id": "MQAy0cQEHRBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Entendendo o Código**\n",
        "\n",
        "- **`__init__`**:\n",
        "  - A função `__init__` inicializa as duas camadas lineares (`linear1` e `linear2`) do modelo. A PyTorch cuida da inicialização adequada dos parâmetros que você especifica.\n",
        "  - `D_in`: Dimensão da entrada.\n",
        "  - `H`: Dimensão da camada oculta.\n",
        "  - `D_out`: Dimensão da saída.\n",
        "\n",
        "- **`forward`**:\n",
        "  - Na função `forward`, aplicamos a primeira camada linear aos dados de entrada `x`, depois aplicamos a função de ativação ReLU, e em seguida, aplicamos a segunda camada linear.\n",
        "  - `h_relu`: Contém as ativações após a primeira camada e a aplicação da função ReLU.\n",
        "  - `y_pred`: A saída prevista pelo modelo após a segunda camada.\n",
        "\n",
        "\n",
        "#### **Dimensões do Input e Batch Size**\n",
        "\n",
        "O módulo assume que a primeira dimensão de `x` é o tamanho do batch. Se a entrada da rede for simplesmente um vetor de dimensão 100 e o tamanho do batch for 32, então a dimensão de `x` seria `(32, 100)`."
      ],
      "metadata": {
        "id": "k4C7kwEdHdm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "# N é o tamanho do batch; D_in é a dimensão da entrada;\n",
        "# H é a dimensão da camada oculta; D_out é a dimensão da saída.\n",
        "N, D_in, H, D_out = 32, 100, 50, 10\n",
        "\n",
        "# Crie Tensores aleatórios para armazenar entradas e saídas, e encapsule-os em Variáveis\n",
        "x = Variable(torch.randn(N, D_in))  # dim: 32 x 100\n",
        "\n",
        "# Construa nosso modelo instanciando a classe definida acima\n",
        "model = TwoLayerNet(D_in, H, D_out)\n",
        "\n",
        "# Passagem direta: Computa y previsto passando x ao modelo\n",
        "y_pred = model(x)   # dim: 32 x 10"
      ],
      "metadata": {
        "id": "PxKYWmfJH5gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nj3uQFN5X4X",
        "outputId": "6ac35403-e6cf-4b87-ad90-3456402a64f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model structure: {model}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p68EeUB0UEjF",
        "outputId": "b9d173e1-3f5e-40e1-c6e7-211b37821338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure: TwoLayerNet(\n",
            "  (linear1): Linear(in_features=100, out_features=50, bias=True)\n",
            "  (linear2): Linear(in_features=50, out_features=10, bias=True)\n",
            ")\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Modelos Mais Complexos**\n",
        "\n",
        "Modelos mais complexos seguem o mesmo layout básico, onde você define as camadas no construtor e implementa a lógica de passagem direta na função `forward`. Em posts subsequentes, podemos explorar arquiteturas mais avançadas, como redes convolucionais e redes recorrentes. Se precisar de mais exemplos ou explicações detalhadas, estou à disposição!"
      ],
      "metadata": {
        "id": "cvaPrDk3IBxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loss Function**\n",
        "\n",
        "O PyTorch oferece várias funções de perda padrão no módulo `torch.nn` que você pode utilizar. Uma das mais comuns para problemas de classificação multiclasse é a `CrossEntropyLoss`. Vamos explorar como calcular essa perda.\n",
        "\n",
        "#### **Exemplo: Cross Entropy Loss**\n",
        "\n",
        "Suponha que seu modelo resolva um problema de classificação multiclasse com `C` classes. Para um batch de tamanho `N`, a saída do modelo (`out`) é uma variável PyTorch de dimensão `NxC`, obtida ao passar um batch de entrada pelo modelo. Temos também uma variável `target` de tamanho `N`, onde cada elemento é a classe correta para cada exemplo, ou seja, um rótulo em `[0,...,C-1]`.\n",
        "\n",
        "Você pode definir a função de perda e calcular a perda da seguinte maneira:"
      ],
      "metadata": {
        "id": "pHpNulvtI2C-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Suponha que temos um batch de dados com 32 amostras e 10 classes\n",
        "N, C = 32, 10  # N: tamanho do batch, C: número de classes\n",
        "\n",
        "# Criando um tensor de previsões 'out' com dimensões NxC (32x10)\n",
        "out = torch.randn(N, C, requires_grad=True)  # Previsões do modelo (logits)\n",
        "\n",
        "# Criando um tensor de rótulos verdadeiros 'target' com tamanho N (32)\n",
        "target = torch.randint(0, C, (N,))  # Rótulos verdadeiros para cada amostra"
      ],
      "metadata": {
        "id": "4F-pgpFJL4rQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo a função de perda Cross Entropy\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Calculando a perda\n",
        "loss = loss_fn(out, target)\n",
        "\n",
        "print(f\"Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9TIKBn4I42C",
        "outputId": "50a11725-750c-46ea-e993-30970b244e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.7162721157073975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Escrevendo sua Própria Função de Perda**\n",
        "\n",
        "O PyTorch facilita a criação de funções de perda personalizadas. Vamos ver como escrever uma função de perda Cross Entropy personalizada:"
      ],
      "metadata": {
        "id": "f_xa-REBI4SD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def myCrossEntropyLoss(outputs, labels):\n",
        "    batch_size = outputs.size()[0]            # tamanho do batch\n",
        "    outputs = F.log_softmax(outputs, dim=1)   # calcula o log dos valores softmax\n",
        "    outputs = outputs[range(batch_size), labels] # seleciona os valores correspondentes aos rótulos\n",
        "    return -torch.sum(outputs)/batch_size"
      ],
      "metadata": {
        "id": "DTtPbaYRI_bZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Neste exemplo:\n",
        "- **`F.log_softmax(outputs, dim=1)`**: Aplica a função softmax nos outputs e calcula o log.\n",
        "- **`outputs[range(batch_size), labels]`**: Seleciona os valores correspondentes aos rótulos fornecidos.\n",
        "- **`-torch.sum(outputs)/batch_size`**: Calcula a perda média para o batch.\n",
        "\n",
        "Este é um exemplo simples de como você pode personalizar funções de perda."
      ],
      "metadata": {
        "id": "dKvjgSyEJHzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Otimizador**\n",
        "\n",
        "O pacote `torch.optim` fornece uma interface fácil de usar para algoritmos de otimização comuns. Definir o otimizador é muito simples:\n",
        "\n",
        "#### **Exemplo: Otimizadores SGD e Adam**"
      ],
      "metadata": {
        "id": "SWVMqevLJV9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Escolhendo o otimizador SGD\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Ou escolhendo o otimizador Adam\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "RwPEK6g8JaPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Aqui:\n",
        "- **`model.parameters()`**: Passa os parâmetros do modelo que precisam ser atualizados a cada iteração.\n",
        "- **`lr`**: Define a taxa de aprendizado.\n",
        "- **`momentum`**: É um hiperparâmetro que pode ser usado com o otimizador SGD para acelerar o treinamento em direção a mínimos e reduzir oscilações.\n",
        "\n",
        "Você também pode especificar métodos mais complexos, como taxas de aprendizado por camada ou até por parâmetro.\n",
        "\n",
        "#### **Atualizando os Parâmetros**\n",
        "\n",
        "Após calcular os gradientes com `loss.backward()`, você pode atualizar os parâmetros do modelo chamando `optimizer.step()`:"
      ],
      "metadata": {
        "id": "oyTMbn3nJc6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculando gradientes\n",
        "loss.backward()\n",
        "\n",
        "# Atualizando os parâmetros\n",
        "optimizer.step()"
      ],
      "metadata": {
        "id": "Kdu8PlXMJwqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinamento\n",
        "\n",
        "O núcleo do algoritmo de treinamento em PyTorch pode ser resumido em apenas cinco linhas de código. Esses passos são responsáveis por passar um batch de entradas pelo modelo, calcular a perda, realizar a retropropagação e atualizar os parâmetros do modelo.\n",
        "\n",
        "```python\n",
        "output_batch = model(train_batch)           # computa a saída do modelo\n",
        "loss = loss_fn(output_batch, labels_batch)  # calcula a perda\n",
        "\n",
        "optimizer.zero_grad()  # limpa gradientes anteriores\n",
        "loss.backward()        # computa os gradientes de todas as variáveis em relação à perda\n",
        "\n",
        "optimizer.step()   \n",
        "```\n",
        "\n",
        "#### **Explicação das Etapas:**\n",
        "\n",
        "1. **`output_batch = model(train_batch)`**: Passa um batch de dados de treinamento pelo modelo para obter as previsões. Aqui, `train_batch` é um tensor que representa o batch de dados de entrada e `output_batch` é o tensor das saídas do modelo para esse batch.\n",
        "\n",
        "2. **`loss = loss_fn(output_batch, labels_batch)`**: Calcula a função de perda comparando as previsões do modelo (`output_batch`) com os rótulos reais (`labels_batch`). A função de perda é usada para quantificar o quão errado o modelo está nas suas previsões.\n",
        "\n",
        "3. **`optimizer.zero_grad()`**: Zera os gradientes dos parâmetros do modelo. No PyTorch, os gradientes são acumulados por padrão, então é importante limpá-los antes de calcular novos gradientes para evitar acumulação indesejada.\n",
        "\n",
        "4. **`loss.backward()`**: Executa a backpropagation, calculando os gradientes de todos os parâmetros do modelo em relação à perda. Isso é crucial para o ajuste dos pesos do modelo na próxima etapa.\n",
        "\n",
        "5. **`optimizer.step()`**: Atualiza os parâmetros do modelo com base nos gradientes calculados na etapa anterior. Esse passo aplica o algoritmo de otimização (como SGD, Adam, etc.) para minimizar a função de perda e, consequentemente, melhorar o desempenho do modelo.\n",
        "\n",
        "Cada uma dessas variáveis (`train_batch`, `labels_batch`, `output_batch` e `loss`) é um tensor PyTorch e permite que derivadas sejam calculadas automaticamente, facilitando o processo de treinamento de modelos."
      ],
      "metadata": {
        "id": "Uu9AKhXnPzRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU\n",
        "\n"
      ],
      "metadata": {
        "id": "XQ8Dh5Xlw5BK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTaDDSZSw7K9",
        "outputId": "d61ddf80-fa5c-4e4b-b0c4-bd0ead317600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = TwoLayerNet(D_in, H, D_out).to(device)\n"
      ],
      "metadata": {
        "id": "TIetwfB8w-Vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save and Load"
      ],
      "metadata": {
        "id": "Q7t69nHFxfRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilLnTSHpz1OJ",
        "outputId": "5f6bbd3e-6eaa-4268-e3d7-99d47e61691f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n"
      ],
      "metadata": {
        "id": "sQQY5ebwzpaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg16(weights='IMAGENET1K_V1')\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/mestrado/monitoria/vgg16_model_weights.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA7Cnigizp2I",
        "outputId": "3d7af74d-5c22-42a4-85a3-870c4de38421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:09<00:00, 60.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg16() # we do not specify ``weights``, i.e. create untrained model\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/mestrado/monitoria/vgg16_model_weights.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUksw8J-zqJ5",
        "outputId": "34165ec6-38be-4b25-b3ff-89eccd3af977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-cbe737dc6f02>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/content/drive/MyDrive/mestrado/monitoria/vgg16_model_weights.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício\n",
        "\n",
        "Sua tarefa é construir uma rede neural simples em PyTorch para classificar as imagens do FashionMNIST.\n"
      ],
      "metadata": {
        "id": "WYV5rnVz3q-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Referências:\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/intro.html\n",
        "\n",
        "https://cs230.stanford.edu/blog/pytorch/\n",
        "\n",
        "https://www.dataquest.io/blog/pytorch-for-beginners/"
      ],
      "metadata": {
        "id": "6TYYQdT8Tt8L"
      }
    }
  ]
}